import random

class MarkovChainTextGenerator:
    def __init__(self, text, n=2):
        """
        Initializes the Markov Chain with a given text.
        
        Parameters:
            text (str): The input text to train the Markov Chain.
            n (int): The order of the Markov Chain (n-gram). Default is 2 (bigram model).
        """
        self.n = n
        self.model = self.build_markov_model(text)
        
    def build_markov_model(self, text):
        """
        Builds the Markov Chain model from the given text.
        
        Parameters:
            text (str): The input text to train the Markov Chain.
        
        Returns:
            dict: A dictionary representing the Markov Chain model.
        """
        model = {}
        words = text.split()
        
        for i in range(len(words) - self.n + 1):
            current_state = tuple(words[i:i + self.n - 1])
            next_word = words[i + self.n - 1]
            
            if current_state not in model:
                model[current_state] = {}
            if next_word not in model[current_state]:
                model[current_state][next_word] = 0
            model[current_state][next_word] += 1
        
        return model

    def generate_text(self, length=50):
        """
        Generates text based on the Markov Chain model.
        
        Parameters:
            length (int): The length of the generated text. Default is 50 words.
        
        Returns:
            str: The generated text.
        """
        if not self.model:
            return ""
        
        # Start with a random initial state
        current_state = random.choice(list(self.model.keys()))
        output = list(current_state)
        
        for _ in range(length - self.n + 1):
            if current_state not in self.model:
                break
            
            next_words = self.model[current_state]
            next_word = self._choose_next_word(next_words)
            
            output.append(next_word)
            current_state = tuple(output[-(self.n - 1):])
        
        return ' '.join(output)

    def _choose_next_word(self, next_words):
        """
        Chooses the next word based on the probability distribution.
        
        Parameters:
            next_words (dict): A dictionary of possible next words and their frequencies.
        
        Returns:
            str: The chosen next word.
        """
        total = sum(next_words.values())
        r = random.uniform(0, total)
        s = 0
        
        for word, frequency in next_words.items():
            s += frequency
            if r <= s:
                return word

        return random.choice(list(next_words.keys()))


# Example usage
if __name__ == "__main__":
    text = ("This is an example text for generating some sample output. "
            "The Markov Chain model will use this text to create new sentences. "
            "Feel free to modify the text to see how the model behaves.")
    
    markov_chain = MarkovChainTextGenerator(text, n=2)  # Using a bigram model
    generated_text = markov_chain.generate_text(length=30)
    print("Generated Text:")
    print(generated_text)
